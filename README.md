# deepseek-offline README

The "deepseek-offline" extension allows you to run the DeepSeek R1 model locally in VS Code, enabling offline chat interactions with the model for tasks such as deep learning and AI research.

## Features
- Run DeepSeek R1 offline for local AI model interactions.
- Stream responses from the model in real-time.
- Simple, intuitive user interface within VS Code.

## Requirements
- Node.js v16 or higher
- VS Code v1.60 or higher
- Required npm packages: `ollama`, `vscode`

## Extension Settings
This extension adds the following settings:
- `deepseek.enable`: Enables or disables the deepseek chat feature.
- `deepseek.model`: Set the model name for DeepSeek.

## Known Issues
- None at the moment.

## Release Notes
### 1.0.0
Initial release of DeepSeek Offline.

### 1.0.1
Bug fix for chat streaming.

## For more information
- [Visual Studio Code's Markdown Support](http://code.visualstudio.com/docs/languages/markdown)